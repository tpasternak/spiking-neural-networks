Plastyczność synaptyczna odnosi się do zdolności połączeń synaptycznych do zmiany swojej przewodności, która jest uważana za podstawowy mechanizm uczenia i pamięci w biologicznych sieciach neuronowych. Współistnieją ze sobą różnorakie formy plastyczności synaptycznej. Różnią się one przede wszystkim na skali czasu: niektóre procesy wygasają w czasie rzędu 10-100 ms, a inne - np. długotrwała depresja (ang. \textbf{LTD} - \textit{Long Term Depression}) utrzymują się przez wiele godzin, dni lub dłużej. Procesy plastyczności różnią się także warunkami koniecznymi do indukcji. Niektóre zależą wyłącznie od historii presynaptycznej stymulacji, niezależnie od postsynaptycznych odpowiedzi. Inne formy plastyczności zależą od współwystępowania odpowiednich pre- i postsynaptycznej odpowiedzi, na czasową kolejność pre- i postsynaptycznych impulsów oraz prawdopodobnie innych czynników, takich jak koncentracja określonych substancji chemicznych. 
W niniejszej pracy dyskutowane są różne modele uczenia impulsowych sieci neuronowych które wykorzystują plastyczność synaptyczną opartą na zależnościach czasowych impulsów.
\subsection{Uczenie bez nadzoru}
W 1949 roku Donald Hebb po raz pierwszy odpowiedział na pytanie w jaki sposób synapsy zmieniają swe wagi tak, czy przechowywać informacje. Matematycznie jego idea może być wyrażona jako: $\Delta w_{ji} \infty \mu_j \mu_i$, gdzie $\Delta w_{ji}$ odnosi się do zmiany siły synaptycznego połączenia $w_{ji}$ pomiędzy presynaptycznym neuronem $i$, a postsynaptyczną komórką $j$; $\mu_i, \mu_j$ wyrażają aktywność tych neuronów. Zgodnie z formułą Hebba, połączenie $w_{ji}$ jest wzmacniane, gdy neurony $i$ i $j$ są jednocześnie aktywne. Równanie to nie opisywało synaptycznej depresji. Jedynie późniejsze badania teoretyczne i eksperymentalne pomogły ustalić warunki, przy których mogło do niej dojść.
Modyfikując przewodności synaptyczne, procesy Hebba prowadzą do reorganizacji połączeń wewnątrz sieci neuronowej i przy pewnych warunkach mogą tworzyć nowe funkcje, takie jak grupowanie wejść, rozpoznawanie wzorców, redukcję wymiarowości, formację pamięci asocjacyjnych lub samoorganizujących map. Wytworzenie tych własciwości poprzez process Hebba jest powszechnie znany jako uczenie bez nadzoru, gdyż nie stawia się sieci żadnego konkretnego celu uczenia i nie jest potrzebna żadna korelacja w procesie tworzenia funkcji wewnątrz sieci. 
Wyrażenia $\mu_i, \mu_j$ w formule Hebba tradycyjnie były interpretowane jako częstości impulsów neuronów. Niedawne odkrycia z dziedziny neurofizjologii sugerują jednak, że plastyczność Hebba może być również zmieniana czasem wystąpienia poszczególnych impulsów. Co więcej, dowody z komórek hippokampa wskazują, że kolejność wystąpienia impulsów pre- i postsynaptycznych mogą indukować różne procesy Hebba. W jednym eksperymencie modyfikowano relatywny czas między dotarciem presynaptycznego impulsów w synapsie a postsynaptycznym potencjałem czynnościowym \cite{Markram97}. Zaobserwowano, że zmiana w przewodności synaptycznej po kilku iteracjach eksperymentu była funkcją relatywnych różnic w czasach impulsów. Generalnie rzecz biorąc, presynaptyczne impulsy występujące przed postsynaptycznymi indukowały wzmocnienie, podczas gdy odwrotna kolejność powodowała depresję synaptyczną. Zjawisko to nazwano plastycznością zależną od czasu impulsów (ang. \textbf{STDP} - \textit{Spike timing Dependent Plasticity}). W niektórych synapsach obserwowano odwrotne zjawisko, teraz znane jako Anty-STDP.
Co ciekawe, zależność plastyczności synaptycznej od czasu występowania impulsów była przewidziana teoretycznie. Zaproponowano model, wyrażony jako: $\frac{d}{dt} w_{ji}(t) = a_0 + a_1 S_i(t) + a_2 S_j(t) + a_3 S_i(t) \overline{S_j}(t) + a_4 \overline{S_i}(t)S_j(t)$, gdzie $w_{ji}(t)$ jest przewodnością połączenia synaptycznego między neuronem $i$ oraz $j$; $S_i(t)$ i $S_j(t)$ są paczkami impulsów pre- i postsynaptycznych, a $\overline{S_i}(t)$ i $\overline{S_j}(t)$ to wersje $S_i(t)$ i $S_j(t)$, po filtracji dolnoprzepustowej. Współczynniki $a_0,...,a_4$ są stałymi kontrolującymi szybkość zmian przewodności synaptycznej. 
Powyższe równanie zakłada, że prócz spadku niezależnego od poziomu aktywności ($a_0$) i współczynników Hebba $a_3 S_i(t)\overline{S_j}(t), a_4 \overline{S_i}(t) S_j(t)$, zmiany w potencjale synaptycznym mogą wynikać z indywidualnych impulsów po stronie pre- lub postsynaptycznej, nawet w przypadku braku reakcji po drugiej stronie synapsy. Odpowiednio dobierając współczynniki powyższego równania, jesteśmy w stanie zamodelować proces STDP, Anty-STDP lub inne.

\subsection{Uczenie z nadzorem}
Uczenie z nadzorem jest wykorzystywane w sztucznych sieciach neuronowych od początkowych lat teorii obliczeń neuronowych. Niedawno zgromadzono więcej dowodów na to, że takie uczenie jest również wykorzystywane przez mózg \cite{Knudsen94}. Najbardziej udokumentowanym zjawiskiem tego rodzaju jest uczenie centralnego układu nerwowego, a zatem związane z kontrolą ruchową. W szczególności, uczenie z nauczycielem jest najprawdopodobniej wykorzystywane przez ośrodki ruchowe do formowania wewnętrznych reprezentacji ciała i otoczenia.
Sygnały uczące mają formę szkieletów aktywności, które mają zostać zreprodukowane. W układzie nerwowym sygnały te są dostarczane do modułów uczących poprzez zmysły lub od innych neuronowych struktur nadzorczych. Nie wiemy jednak jaka jest dokładna reprezentacja neuronowych sygnałów uczących oraz jak neurony biologiczne uczą się generować zadane wyjścia na ich podstawie. 
Spośród niewielu rozpoznanych metod uczenia z nauczycielem sieci impulsowych, uczenie Hebba z nadzorem (ang. \textbf{SHL} - \textit{Supervised Hebbian Learning}) oferuje prawdopodobnie najbardziej oczywiste rozwiązanie dla implementacji nadzoru w sposób realistyczny biologicznie. Zgodnie z tym podejściem impulsowy proces Hebba jest nadzorowany przez dodatkowy sygnał uczący, który wzmacnia neuron postsynaptyczny, by wystrzeliwał w zadanych momentach czasowych i pozostawał uśpiony w pozostałych. Sygnał uczący jest zazwyczaj transmitowany do neuronu w formie ładunków synaptycznych lub ładunków wstrzykiwanych wewnątrzkomórkowo. Podczas badań metody dostrzeżono jej pewne ograniczenie: ponieważ ładunki uczące tłumią wszystkie niepożądane wystrzały w trakcie treningu, jedyne korelacja między aktywnością pre- i postsynaptyczną zachodzi w okolicy zadanych czasów wystrzałów. W pozostałym czasie, nie ma korelacji, nie ma mechanizmu osłabiającego wagi synaptycznych, które powodują wystrzał neuronu w niepożądanych okresach czasu. Stabilne rozwiązania w SHL mogą zostać osiągnięte wyłącznie przy dodatkowych założeniach (regułach uczących). 
Problemy te były zaadresowane w algorytmie ReSuMe \cite{Ponulak2011}. Podobnie do SHL, wykorzystuje on procesy Hebba, lecz sygnał uczący powinien mieć jak najmnieszy wpływ na postsynaptyczny potencjał somatyczny membrany. W ReSuMe, waga synaptyczna jest modyfikowana zgodnie z poniższym równaniem:
 
$\frac{d}{dt} w_{ji}(t) = a \left[S_d(t) - S_j(t) \right] \overline{S_i}(t)$, gdzie a - szybkość uczenia, $S_d$ - referencyjny ciąg impulsów, $S_j$ - odpowiedź sieci, $\overline{S_i}(t)$ - ciąg impulsów wejściowych, po użyciu filtra dolnoprzepustowego.

Równanie opisuje ReSuMe jako metodę łączącą dwa procesy Hebba: pierwszego zdefiniowanego na zadanej i presynaptycznej paczce impulsów, oraz drugiego, anty-Hebbowego, zdefiniowanego na paczkach impulsów pre- i postsynaptycznych. Warto zauważyć, że prawa strona równania ma podobną postać do znanej nam reguły Widrowa-Hoffa.

O ile przedstawione wyżej metody z powodzeniem uczą sieci jednowarstwowe, bardziej pożądane są sposoby uczenia sieci wielowarstwowych i rekurencyjnych, z uwagi na ich zwiększone możliwości obliczeniowe. Niestety, implementacja algorytmu wstecznej propagacji dla sieci impulsowych jest utrudniona, ze względu na złożoną i ich często nieciągłą dynamikę. Pierwszy zaproponowany algorytm, zwany SpikeProp, wykorzystał powyższą, przy jednym poważnym ograniczeniu - każdy neuron mógł wystrzelić tylko raz w trakcie okresu uczenia. Z biegiem czasu algorytm został jednak udoskonalony i z powodzeniem jest wykorzystywany w praktyce.

\subsection{Uczenie w obecności sygnału nagrody} 

Zwierzęta w przyrodzie uczą się nowych zachowań nie tylko w obecności bezpośrednich instrukcji, lecz częściej rozważając dostępne opcje w obecności sygnałów nagrody. W procesie prób i błędów najlepsze wybory są wzmacniane, a złe - osłabiane sygnałami kary. Taki sposób uczenia został już pomyślnie wykorzystany w dziedzinie machine learning. Dostrzeżono również, że w podobny sposób uczy się ośrodek dopaminergiczny. Ściślej, koncentracja dopaminy, neuromodulatora emitowanego przez komórki dopaminergiczne, kontroluje procesy plastyczności w wielu obszarach mózgu. 

Na postawie powyższych obserwacji powstało kilka metod uczenia w obecności sygnału nagrody. Wiele z nich może było opisanych przez następującą, generyczną formułę: 
$\frac{d}{dt}w_{i,j}(t) = c_{ji}(t)d(t)$, gdzie $w_{ji}$ oznacza wagę połączenia synaptycznego między neuronem $i$ oraz $j$, $c_{ji}(t)$ to podatność tej synapsy na zmiany.

Zaproponowane modele łączące teorię nauki przy udziale nagrody / kary i plastyczność synaptyczną opartą na kodowaniu impulsowym zostały wykorzystane do wyjaśnienia wielu zjawisk zaobserwowanych eksperymentalnie. Impulsowe sieci neuronowe zostały również z powodzeniem wykorzystane do rozwiązania szeregu zadań inżynierskich. 
